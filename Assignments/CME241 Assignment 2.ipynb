{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdhOCFVvtcHe"
      },
      "source": [
        "# Stanford CME 241 (Winter 2026) - Assignment 2\n",
        "\n",
        "**Due: Friday, February 13 @ 11:59 PM PST on Gradescope.**\n",
        "\n",
        "Assignment instructions:\n",
        "- Make sure each of the subquestions have answers\n",
        "- Ensure that group members indicate which problems they're in charge of\n",
        "- Show work and walk through your thought process where applicable\n",
        "- Empty code blocks are for your use, so feel free to create more under each section as needed\n",
        "- Document code with light comments (i.e. 'this function handles visualization')\n",
        "\n",
        "Submission instructions:\n",
        "- When complete, fill out your publicly available GitHub repo file URL and group members below, then export or print this .ipynb file to PDF and upload the PDF to Gradescope.\n",
        "\n",
        "*Link to this ipynb file in your public GitHub repo (replace below URL with yours):*\n",
        "\n",
        "https://github.com/my-username/my-repo/assignment-file-name.ipynb\n",
        "\n",
        "*Group members (replace below names with people in your group):*\n",
        "- Jackson Fang\n",
        "- Xiao Huang\n",
        "- Shunyu Yao"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-E-yxUMtcHh"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm5Rbg7RtcHi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb9XG23FtcHi"
      },
      "source": [
        "## Question 1: Job-Hopping and Wages-Utility-Maximization (Led by Xiao Huang)\n",
        "\n",
        "You are a worker who starts every day either employed or unemployed. If you start your day employed, you work on your job for the day (one of $n$ jobs, as elaborated later) and you get to earn the wage of the job for the day. However, at the end of the day, you could lose your job with probability $\\alpha \\in [0,1]$, in which case you start the next day unemployed. If at the end of the day, you do not lose your job (with probability $1-\\alpha$), then you will start the next day with the same job (and hence, the same daily wage).\n",
        "\n",
        "On the other hand, if you start your day unemployed, then you will be randomly offered one of $n$ jobs with daily wages $w_1, w_2, \\ldots w_n \\in \\mathbb{R}^+$ with respective job-offer probabilities $p_1, p_2, \\ldots p_n \\in [0,1]$ (with $\\sum_{i=1}^n p_i = 1$). You can choose to either accept or decline the offered job. If you accept the job offer, your day progresses exactly like the **employed-day** described above (earning the day's job wage and possibly (with probability $\\alpha$) losing the job at the end of the day). However, if you decline the job offer, you spend the day unemployed, receive the unemployment wage $w_0 \\in \\mathbb{R}^+$ for the day, and start the next day unemployed.\n",
        "\n",
        "The problem is to identify the optimal choice of accepting or rejecting any of the job offers the worker receives, in a manner that maximizes the infinite-horizon **Expected Discounted-Sum of Wages Utility**. Assume the daily discount factor for wages (employed or unemployed) is $\\gamma \\in [0,1])$. Assume Wages Utility function to be $U(w) = \\log(w)$ for any wage amount $w \\in \\mathbb{R}^+$. The goal is to maximize:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}\\left[\\sum_{u=t}^\\infty \\gamma^{u-t} \\cdot \\log(w_{i_u})\\right]\n",
        "$$\n",
        "\n",
        "at the start of a given day $t$ ($w_{i_u}$ is the wage earned on day $u$, $0 \\leq i_u \\leq n$ for all $u \\geq t$).\n",
        "\n",
        "---\n",
        "\n",
        "### Subquestions\n",
        "\n",
        "#### Part (A): MDP Modeling\n",
        "\n",
        "Express the job-hopping problem as an MDP using clear mathematical notation by defining the following components:\n",
        "\n",
        "1. **State Space**: Define the possible states of the MDP.\n",
        "2. **Action Space**: Specify the actions available to the worker at each state.\n",
        "3. **Transition Function**: Describe the probabilities of transitioning between states for each action.\n",
        "4. **Reward Function**: Specify the reward associated with the states and transitions.\n",
        "5. **Bellman Optimality Equation**: Write the Bellman Optimality Equation customized for this MDP.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (B): Python Implementation\n",
        "\n",
        "Write Python code that:\n",
        "\n",
        "1. Solves the Bellman Optimality Equation (hence, solves for the **Optimal Value Function** and the **Optimal Policy**) with a numerical iterative algorithm.\n",
        "2. Clearly define the inputs and outputs of your algorithm with their types (`int`, `float`, `List`, `Mapping`, etc.).\n",
        "\n",
        "*Note*: For this problem, write the algorithm from scratch without using any prebuilt MDP/DP libraries or code.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (C): Visualization and Analysis\n",
        "\n",
        "1. Plot the **Optimal Value Function** as a function of the state for a specific set of parameters ($n$, $w_1, \\ldots, w_n$, $p_1, \\ldots, p_n$, $\\alpha$, $\\gamma$, $w_0$).\n",
        "2. Include these graphs in your submission.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (D): Observations\n",
        "\n",
        "1. What patterns do you observe in the **Optimal Policy** as you vary the parameters $n$, $\\alpha$, and $\\gamma$?\n",
        "2. Provide a brief discussion of your findings.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRDwiTUmtcHj"
      },
      "source": [
        "### Part (A) Answer\n",
        "\n",
        "<span style=\"color:red\">*\n",
        "In this question, we define two status: employed and unemployed as with respected of the finite time horizon $i\\in\\{1,...,n\\}$, then the employment status will be either employed $E_i$ and unemployed $N_i$.\n",
        "\n",
        "1. State space:\n",
        "- Therefore the state space will be $S=\\{E_1,\\dots,E_n\\}\\cup\\{N_1,\\dots,N_n\\}$.\n",
        "\n",
        "in this question, we need to choose accept or reject the offer in unemployed states.\n",
        "\n",
        "2. Action space: if employed:\n",
        "\n",
        "- At employed states: $A(E_i) = \\{work\\}$     \n",
        "\n",
        "in this question, we need to choose accept or reject the offer in unemployed states.\n",
        "\n",
        "- At unemployed but with offer states: $A(N_i) = \\{accept, reject\\}$.\n",
        "\n",
        "3. Transition function:\n",
        "- if employed:\n",
        "  - $P(E_i | E_i, work) = 1 - \\alpha$\n",
        "  - $P(N_j | E_i, work) = \\alpha * p_j, ∀ j = 1, ..., n$\n",
        "\n",
        "  - 0, o/w\n",
        "- if accept offer at unemployed state:\n",
        "  - $P(E_i | N_i, accept) = 1 - \\alpha$\n",
        "  - $P(N_j | N_i, accept) = \\alpha * p_j, ∀ j = 1, ..., n$\n",
        "  - 0, o/w\n",
        "\n",
        "- From unemployed state O_i, if reject:\n",
        "  - $P(N_j | N_i, reject) = p_j, ∀ j = 1, ..., n$\n",
        "  - 0, o/w\n",
        "\n",
        "4. Reward function:\n",
        "- $R(E_i, work)    = log(w_i)$\n",
        "- $R(N_i, accept)  = log(w_i)$\n",
        "- $R(N_i, reject)  = log(w_0)$\n",
        "\n",
        "5. Bellman Optimality Equation:\n",
        "- For each employed state:\n",
        "  - $V^*(E_i) = log(w_i)+ \\gamma [ (1 - \\alpha) V*(E_i) + \\alpha \\sum_{j=1}^n p_j V*(N_j) ]$.\n",
        "\n",
        "\n",
        "- For each umployed but offered state\n",
        "  - $ V^*(N_i) = \\max\\{log(w_i)+ \\gamma [(1 - \\alpha) V^*(E_i) + \\alpha \\sum_{j=1}^n p_j V^*(N_j)],\n",
        "  log(w_0)+ \\gamma \\sum_{j=1}^n p_j V^*(N_j) \\}$.\n",
        "\n",
        "  if we simpify this with the employed state,\n",
        "  \n",
        "  - $V^*(N_i) = max\\{V^*(E_i), log(w_0) + \\gamma \\sum_j p_jV^*(N_j)\\}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuAsGVb_tcHj"
      },
      "source": [
        "### Part (B) Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSeLTQ8CtcHk"
      },
      "outputs": [],
      "source": [
        "# fill in with Python code\n",
        "\n",
        "from math import log\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "def solve_job_hopping(\n",
        "    n: int,\n",
        "    wages: List[float],\n",
        "    probs: List[float],\n",
        "    alpha: float,\n",
        "    gamma: float,\n",
        "    w0: float,\n",
        "    tol: float = 1e-10, #adjustable\n",
        "    max_iter: int = 100,#adjustable\n",
        ") -> Tuple[List[List[float]], List[int]]:\n",
        "\n",
        "\n",
        "    # v_e[i] = V(E_i), v_n[i] = V(N_i)\n",
        "    v_e = [0.0] * n\n",
        "    v_n = [0.0] * n\n",
        "\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        exp_vn = sum(probs[j] * v_n[j] for j in range(n))  # sum_j p_j V(N_j)\n",
        "\n",
        "        next_v_e = [0.0] * n\n",
        "        next_v_n = [0.0] * n\n",
        "\n",
        "        for i in range(n):\n",
        "            accept_val = log(wages[i]) + gamma * (\n",
        "                (1.0 - alpha) * v_e[i] + alpha * exp_vn\n",
        "            )\n",
        "            reject_val = log(w0) + gamma * exp_vn\n",
        "\n",
        "            next_v_e[i] = accept_val\n",
        "            next_v_n[i] = accept_val if accept_val >= reject_val else reject_val\n",
        "\n",
        "        residual_e = max(abs(next_v_e[i] - v_e[i]) for i in range(n))\n",
        "        residual_n = max(abs(next_v_n[i] - v_n[i]) for i in range(n))\n",
        "        residual = max(residual_e, residual_n)\n",
        "\n",
        "        v_e, v_n = next_v_e, next_v_n\n",
        "        if residual < tol:\n",
        "            break\n",
        "\n",
        "    exp_vn = sum(probs[j] * v_n[j] for j in range(n))\n",
        "    pi_star = [0] * n\n",
        "    for i in range(n):\n",
        "        q_accept = log(wages[i]) + gamma * ((1.0 - alpha) * v_e[i] + alpha * exp_vn)\n",
        "        q_reject = log(w0) + gamma * exp_vn\n",
        "        pi_star[i] = 1 if q_accept >= q_reject else 0\n",
        "\n",
        "    v_star = [v_e, v_n]\n",
        "    return v_star, pi_star\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJGQaB_AtcHk"
      },
      "source": [
        "### Part (C) Answer\n",
        "- I pick $w_{min}=10,w_{max}=100,\\alpha=0.10,\\gamma=0.95,w_0=20.0$ for the plot\n",
        "![a2q1fig1.png](data:image/png;base64,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)\n",
        "<span style=\"color:red\">\n",
        "\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVOQ5EAgtcHk"
      },
      "source": [
        "### Part (D) Answer\n",
        "\n",
        "<span style=\"color:red\">\n",
        "I plotted the optimal action wrt offered wage to show the optimal policy sensitivity to the change in parameters.\n",
        "\n",
        "1. varying $α$\n",
        "- When α gets larger, the probability of losing the job gets higher. When $\\alpha$ gets larger, then the job is more temporary, and there is less incentive to wait for a perfect job, and the optimal action will sadenlly jump to accept the offer with lower wages. And as α gets lower, the job will be more stable, then the optimal action will be rejecting the offer, and there is an incentive to wait longer until finding a good job.\n",
        "2. varying γ\n",
        "- a higher $\\gamma$ means caring more about the future. When gamma increase, more patience will be seen, and will accept the offer with longer wait than lower γ\n",
        "\n",
        "3. varying n\n",
        "- when n gets larger, there are more jobs. When n gets larger, the accepted wage seems converge to a fix point, and the accepted  wage will be lower\n",
        "But also whether increase in n affects the chance of seeing high-wage jobs are important (i.e how does $p_i$ changes). if increasing n adds more high-wage jobs, then the optimal oplicy will be more selective.\n",
        "\n",
        "\n",
        "\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLf3PqWLtcHk"
      },
      "source": [
        "## Question 2: Two-Stores Inventory Control (Led by __Jackson____)\n",
        "\n",
        "We extend the capacity-constrained inventory example implemented in [rl/chapter3/simple_inventory_mdp_cap.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/chapter3/simple_inventory_mdp_cap.py) as a `FiniteMarkovDecisionProcess` (the Finite MDP model for the capacity-constrained inventory example is described in detail in Chapters 1 and 2 of the RLForFinanceBook). Here we assume that we have two different stores, each with their own separate capacities $C_1$ and $C_2$, their own separate Poisson probability distributions of demand (with means $\\lambda_1$ and $\\lambda_2$), their own separate holding costs $h_1$ and $h_2$, and their own separate stockout costs $p_1$ and $p_2$. At 6pm upon stores closing each evening, each store can choose to order inventory from a common supplier (as usual, ordered inventory will arrive at the store 36 hours later). We are also allowed to transfer inventory from one store to another, and any such transfer happens overnight, i.e., will arrive by 6am next morning (since the stores are fairly close to each other). Note that the orders are constrained such that following the orders on each evening, each store's inventory position (sum of on-hand inventory and on-order inventory) cannot exceed the store's capacity (this means the action space is constrained to be finite). Each order made to the supplier incurs a fixed transportation cost of $K_1$ (fixed-cost means the cost is the same no matter how many units of non-zero inventory a particular store orders). Moving any non-zero inventory between the two stores incurs a fixed transportation cost of $K_2$.\n",
        "\n",
        "Model this as a derived class of `FiniteMarkovDecisionProcess` much like we did for `SimpleInventoryMDPCap` in the code repo. Set up instances of this derived class for different choices of the problem parameters (capacities, costs etc.), and determine the Optimal Value Function and Optimal Policy by invoking the function `value_iteration` (or `policy_iteration`) from file [rl/dynamic_programming.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/dynamic_programming.py).\n",
        "\n",
        "Analyze the obtained Optimal Policy and verify that it makes intuitive sense as a function of the problem parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a481efc",
        "outputId": "0623212a-1488-4181-dbb9-cb3e64d3add7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/RL-book')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ab3f52",
        "outputId": "6356fa99-99a6-43a8-f7cf-4c63eb3d1d2b"
      },
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/RL-book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDVelL5stcHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83144b0-df75-4d18-fa9c-7ca2661b0558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MDP Policy Iteration: Optimal Value and Policy\n",
            "----------------------------------------------\n",
            "{NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-51.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-50.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-52.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-49.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-51.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=1)): np.float64(-50.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=0)): np.float64(-52.61489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-52.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-51.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-53.11489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-50.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-52.11489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-54.95629065074789),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=2, on_order_2=0)): np.float64(-49.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=1)): np.float64(-48.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=0)): np.float64(-50.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=2)): np.float64(-47.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=1)): np.float64(-49.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=0)): np.float64(-52.11543559637947),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=1, on_order_2=0)): np.float64(-51.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=1)): np.float64(-50.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=0)): np.float64(-52.11489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=2)): np.float64(-49.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=1)): np.float64(-51.11489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=0)): np.float64(-53.95629065074789),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-53.61489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-52.61489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-54.95629065074789),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-52.11543559637947),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-53.95629065074789),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-56.72104481351034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-53.61489012686437),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=0)): np.float64(-51.25989322867612),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=1, on_order_2=0)): np.float64(-50.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=1)): np.float64(-49.46783754873693),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=2)): np.float64(-48.46783754873693)}\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=2, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=-1)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=-1)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=1)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=1)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "\n",
            "\n",
            "MDP Value Iteration: Optimal Value and Policy\n",
            "---------------------------------------------\n",
            "{NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-53.956297716571555),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-52.11544266220313),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-54.95629771657155),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-52.614897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-53.614897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=0)): np.float64(-53.956297716571555),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=1)): np.float64(-51.114897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=2)): np.float64(-49.25990029449979),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=0)): np.float64(-52.114897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=1)): np.float64(-50.25990029449979),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=1, on_order_2=0)): np.float64(-51.25990029449978),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=0)): np.float64(-52.11544266220313),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=1)): np.float64(-49.259900294499786),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=2)): np.float64(-47.46784461456059),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=0)): np.float64(-50.25990029449978),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=1)): np.float64(-48.46784461456059),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=2, on_order_2=0)): np.float64(-49.46784461456058),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-54.956297716571555),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-52.114897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-50.25990029449979),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-53.114897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-51.25990029449978),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-52.259900294499786),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=0)): np.float64(-52.614897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=1)): np.float64(-50.25990029449978),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=2)): np.float64(-48.46784461456059),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=0)): np.float64(-51.259900294499786),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=1)): np.float64(-49.46784461456058),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=1, on_order_2=0)): np.float64(-50.4678446145606),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-53.614897192688034),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=1)): np.float64(-51.259900294499786),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=2)): np.float64(-49.46784461456058),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=0)): np.float64(-52.259900294499786),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=1)): np.float64(-50.4678446145606),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=2, on_hand_2=2, on_order_1=0, on_order_2=0)): np.float64(-51.46784461456059),\n",
            " NonTerminal(state=TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=0)): np.float64(-56.72105187933399)}\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=2, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=2, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=-1)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=-1)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=1, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=1, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=0, on_order_1=2, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=1, on_order_1=2, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=0, on_hand_2=2, on_order_1=2, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=2, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=1)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=1, on_order_1=1, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=1, on_hand_2=2, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=1)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=0, on_order_1=0, on_order_2=2): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=1, on_order_1=0, on_order_2=1): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "For State TwoStoreState(on_hand_1=2, on_hand_2=2, on_order_1=0, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=0, transfer=0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# fill in with Python code\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Mapping, NamedTuple\n",
        "from rl.markov_decision_process import FiniteMarkovDecisionProcess\n",
        "from rl.policy import FiniteDeterministicPolicy\n",
        "from rl.markov_process import FiniteMarkovProcess, FiniteMarkovRewardProcess\n",
        "from rl.distribution import Categorical\n",
        "from scipy.stats import poisson\n",
        "import itertools\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TwoStoreState:\n",
        "    on_hand_1: int\n",
        "    on_hand_2: int\n",
        "    on_order_1: int\n",
        "    on_order_2: int\n",
        "\n",
        "    def inventory_position_1(self) -> int:\n",
        "        return self.on_hand_1 + self.on_order_1\n",
        "\n",
        "    def inventory_position_2(self) -> int:\n",
        "        return self.on_hand_2 + self.on_order_2\n",
        "\n",
        "class TwoStoreAction(NamedTuple):\n",
        "    order_1: int\n",
        "    order_2: int\n",
        "    transfer: int\n",
        "\n",
        "\n",
        "TwoStoreMapping = Mapping[\n",
        "    TwoStoreState,\n",
        "    Mapping[TwoStoreAction, Categorical[Tuple[TwoStoreState, float]]]\n",
        "]\n",
        "\n",
        "\n",
        "class TwoStoreInventoryMDP(FiniteMarkovDecisionProcess[TwoStoreState, TwoStoreAction]):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        c1: int, c2: int,\n",
        "        l1: float, l2: float,\n",
        "        h1: float, h2: float,\n",
        "        p1: float, p2: float,\n",
        "        k1: float, k2: float\n",
        "    ):\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "        self.h1 = h1\n",
        "        self.h2 = h2\n",
        "        self.p1 = p1\n",
        "        self.p2 = p2\n",
        "        self.k1 = k1\n",
        "        self.k2 = k2\n",
        "\n",
        "        self.dist1 = poisson(l1)\n",
        "        self.dist2 = poisson(l2)\n",
        "\n",
        "        super().__init__(self.get_action_transition_reward_map())\n",
        "\n",
        "    def get_action_transition_reward_map(self) -> TwoStoreMapping:\n",
        "        d = {}\n",
        "\n",
        "        # all possible states\n",
        "        states = [\n",
        "            TwoStoreState(oh1, oh2, oo1, oo2)\n",
        "            for oh1 in range(self.c1 + 1)\n",
        "            for oo1 in range(self.c1 + 1 - oh1)\n",
        "            for oh2 in range(self.c2 + 1)\n",
        "            for oo2 in range(self.c2 + 1 - oh2)\n",
        "        ]\n",
        "\n",
        "        for state in states:\n",
        "            d1 = {}\n",
        "            ip1 = state.inventory_position_1()\n",
        "            ip2 = state.inventory_position_2()\n",
        "\n",
        "            # create all possible actions\n",
        "            min_transfer = -state.on_hand_2\n",
        "            max_transfer = state.on_hand_1\n",
        "\n",
        "            for t in range(min_transfer, max_transfer + 1):\n",
        "                # IP = (On Hand - Transfer) + On Order + New Order\n",
        "\n",
        "                max_o1 = self.c1 - (ip1 - t)\n",
        "                max_o2 = self.c2 - (ip2 + t)\n",
        "\n",
        "                if max_o1 < 0 or max_o2 < 0:\n",
        "                    continue\n",
        "\n",
        "                for o1 in range(max_o1 + 1):\n",
        "                    for o2 in range(max_o2 + 1):\n",
        "                        action = TwoStoreAction(o1, o2, t)\n",
        "\n",
        "                        # calculate cost and rewards\n",
        "\n",
        "                        # fixed Costs\n",
        "                        fixed_cost = 0.0\n",
        "                        if o1 > 0: fixed_cost += self.k1\n",
        "                        if o2 > 0: fixed_cost += self.k1\n",
        "                        if t != 0: fixed_cost += self.k2\n",
        "\n",
        "                        # holding cost\n",
        "\n",
        "                        eff_oh1 = state.on_hand_1 - t\n",
        "                        eff_oh2 = state.on_hand_2 + t\n",
        "                        holding_cost = (self.h1 * eff_oh1) + (self.h2 * eff_oh2)\n",
        "\n",
        "                        base_reward = -(fixed_cost + holding_cost)\n",
        "\n",
        "                        # effective  ip available to meet demand\n",
        "                        # on-order arrives now\n",
        "                        avail_1 = eff_oh1 + state.on_order_1\n",
        "                        avail_2 = eff_oh2 + state.on_order_2\n",
        "\n",
        "                        outcomes = {}\n",
        "\n",
        "                        # Loop over demand scenarios for Store 1\n",
        "                        # We go up to avail_1 (demand met) and treat avail_1+1 as \"stockout\" bucket\n",
        "                        for d1_val in range(avail_1 + 1):\n",
        "                            if d1_val < avail_1:\n",
        "                                p1 = self.dist1.pmf(d1_val)\n",
        "                                next_oh1 = avail_1 - d1_val\n",
        "                                cost1 = 0.0\n",
        "                            else:\n",
        "                                # tail probability for stockout\n",
        "                                prob_le = self.dist1.cdf(avail_1 - 1) if avail_1 > 0 else 0.0\n",
        "                                p1 = 1.0 - prob_le\n",
        "                                next_oh1 = 0\n",
        "                                # expected stockout quantity, expected demand(total) - expected sales\n",
        "                                expected_shortage_1 = self.l1 - avail_1 * (1 - self.dist1.pmf(avail_1)/p1)\n",
        "                                cost1 = self.p1 * expected_shortage_1\n",
        "\n",
        "                            # store 2\n",
        "                            for d2_val in range(avail_2 + 1):\n",
        "                                if d2_val < avail_2:\n",
        "                                    p2 = self.dist2.pmf(d2_val)\n",
        "                                    next_oh2 = avail_2 - d2_val\n",
        "                                    cost2 = 0.0\n",
        "                                else:\n",
        "                                    prob_le = self.dist2.cdf(avail_2 - 1) if avail_2 > 0 else 0.0\n",
        "                                    p2 = 1.0 - prob_le\n",
        "                                    next_oh2 = 0\n",
        "                                    expected_shortage_2 = self.l2 - avail_2 * (1 - self.dist2.pmf(avail_2)/p2)\n",
        "                                    cost2 = self.p2 * expected_shortage_2\n",
        "\n",
        "                                # Combine into Joint Outcome\n",
        "                                joint_prob = p1 * p2\n",
        "                                total_reward = base_reward - (cost1 + cost2)\n",
        "                                next_state = TwoStoreState(next_oh1, next_oh2, o1, o2)\n",
        "\n",
        "                                # Add to probability mass\n",
        "                                pair = (next_state, total_reward)\n",
        "                                outcomes[pair] = outcomes.get(pair, 0.0) + joint_prob\n",
        "\n",
        "                        d1[action] = Categorical(outcomes)\n",
        "\n",
        "            d[state] = d1\n",
        "\n",
        "        return d\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    from pprint import pprint\n",
        "    from rl.dynamic_programming import value_iteration_result\n",
        "    from rl.dynamic_programming import evaluate_mrp_result, policy_iteration_result, value_iteration_result\n",
        "    from rl.markov_process import FiniteMarkovProcess\n",
        "    from rl.policy import FiniteDeterministicPolicy\n",
        "    from pprint import pprint\n",
        "\n",
        "    # config\n",
        "    user_gamma = 0.9\n",
        "\n",
        "    two_store_mdp = TwoStoreInventoryMDP(\n",
        "        c1=2, c2=2, l1=0.5, l2=0.5, h1=1.0, h2=1.0, p1=10.0, p2=10.0, k1=2.0, k2=0.5\n",
        "    )\n",
        "\n",
        "\n",
        "    # policy iteration results\n",
        "    print(\"\\nMDP Policy Iteration: Optimal Value and Policy\")\n",
        "    print(\"----------------------------------------------\")\n",
        "    opt_vf_pi, opt_policy_pi = policy_iteration_result(two_store_mdp, gamma=user_gamma)\n",
        "    pprint(opt_vf_pi)\n",
        "    print(opt_policy_pi)\n",
        "\n",
        "    # value iteration results\n",
        "    print(\"\\nMDP Value Iteration: Optimal Value and Policy\")\n",
        "    print(\"---------------------------------------------\")\n",
        "    opt_vf_vi, opt_policy_vi = value_iteration_result(two_store_mdp, gamma=user_gamma)\n",
        "    pprint(opt_vf_vi)\n",
        "    print(opt_policy_vi)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal value function and optimal policy makes intuitive sense.\n",
        "1. Balancing the transfer and order from suppliers. When the state is (0, 2, 0, 0), where store 1 is empty but store 2 is full—the policy chooses to transfer from store 2 to store 1 a 1 stock. Since a transfer arrives in 12 hours while a supplier order takes 36 hours, the model pays the lower $K_2$ cost to provide immediate relief to store 1, significantly reducing the high expected shortage penalty.\n",
        "\n",
        "2. In state (0, 0, 0, 0), the policy chooses to order 2 for both stores.Since ecause there is a fixed cost $K_1$ (2.0) per order, it is inefficient to place small, frequent orders. When inventory is depleted, the model fill it to the maximum to avoid frequent fixed cost.\n",
        "\n",
        "3. Another example is in optimal value function,\n",
        "\n",
        "    For State TwoStoreState(on_hand_1=1, on_hand_2=0, on_order_1=1, on_order_2=0): Do Action TwoStoreAction(order_1=0, order_2=1, transfer=1).\n",
        "\n",
        "    Since there is already order to fill the c1, and there is nothing in c2 yet, having c1 transfer 1 unit to c2 can avoid large stockout cost, while ordering 1 more unit for c2 would not exceed the maximun."
      ],
      "metadata": {
        "id": "Nh5FfqjYfAur"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vspSKk5tcHl"
      },
      "source": [
        "## Question 3: Dynamic Price Optimization (Led by Xiao Huang)\n",
        "\n",
        "You own a supermarket, and you are $T$ days away from Halloween 🎃. You have just received $M$ Halloween masks from your supplier. You want to dynamically set the selling price of the Halloween masks at the start of each day in a manner that maximizes your **Expected Total Sales Revenue** for Halloween masks this season (assume no one will buy Halloween masks after Halloween).\n",
        "\n",
        "Assume that for each of the $T$ days, you are required to select a price for that day from one of $N$ prices $p_1, p_2, \\dots, p_N \\in \\mathbb{R}$, and that price is the selling price for all masks on that day. Assume that the customer demand for the number of Halloween masks on any day is governed by a Poisson probability distribution with mean $\\lambda_i \\in \\mathbb{R}$ if you select that day’s price to be $p_i$ (where $i$ is a choice among $1, 2, \\dots, N$).\n",
        "\n",
        "Note that on any given day, the demand could exceed the number of Halloween masks you have in the store, in which case the number of masks sold on that day will be equal to the number of Halloween masks you had at the start of that day.\n",
        "\n",
        "We spoke about this example in class - referencing the slides here (if needed) could be helpful!\n",
        "\n",
        "---\n",
        "\n",
        "### Subquestions\n",
        "\n",
        "#### Part (A): Bellman Optimality Equation\n",
        "\n",
        "Write the **Bellman Optimality Equation** customized to this Markov Decision Process (MDP). Essentially, you need to express the **Optimal Value Function** $v_*$ recursively based on taking the best action in the current state and based on the subsequent random customer demand that would produce the appropriate reward and take you to the next state.\n",
        "\n",
        "**Note**: The probability mass function of a Poisson distribution with mean $\\lambda \\in \\mathbb{R}$ is given by:\n",
        "\n",
        "$$\n",
        "f(k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}, \\quad k = 0, 1, 2, \\dots\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (B): Boundary Conditions\n",
        "\n",
        "To be able to solve the $v_*$ recursion, you need to know the values of $v_*$ for the boundary case (boundary states). Write down the boundary case(s) for the $v_*$ recursion.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (C): Numerical Solution\n",
        "\n",
        "You can solve this $v_*$ recursion (hence, solve for the **Optimal Policy** $\\pi_*$) with a numerical recursive algorithm (essentially a special form of Dynamic Programming algorithm customized to this problem).\n",
        "\n",
        "Write Python code for this algorithm that would enable you to dynamically set the selling price at the start of each day. Clearly define the inputs and outputs of your algorithm with their types (`int`, `float`, `List`, `Mapping`, etc.).\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiDOtw_tcHm"
      },
      "source": [
        "### Part (A) Answer\n",
        "\n",
        "<span style=\"color:red\">\n",
        "1. We denote the inventory at t starts at I, and the demand $d~Poisson(λ_i)$, and the amount sold at the day is $ min(I_t, d)$\n",
        "\n",
        "- when t = 0,  then $I_0 = M$\n",
        "\n",
        "Therefore, $I_{t+1} = I_t-min(I_t, d_t)$\n",
        "\n",
        "\n",
        "- when $0\\leq t<T$\n",
        "\n",
        "  - $V^{*}(t, I_t)=\\max_{1 \\le i \\le N}\\sum_{d=0}^{\\infty}\\frac{e^{-\\lambda_i}\\lambda_i^{d}}{d!}\\Bigl(p_i \\min(I_t,d) + V^*\\bigl(t+1,\\; I_t-\\min(I_t,d)\\bigr)\n",
        "\\Bigr)$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wsr-824tcHm"
      },
      "source": [
        "### Part (B) Answer\n",
        "\n",
        "<span style=\"color:red\">\n",
        "the boundary condition is\n",
        "$V^*(t, I) = 0, \\forall I$\n",
        "\n",
        "\n",
        "\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DaXR8astcHm"
      },
      "source": [
        "### Part (C) Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cM3-11-GtcHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36308b7-8dea-4b85-ca62-93c1e66eba35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 | 30 | 3 | 12.0\n",
            "1 | 30 | 2 | 10.0\n",
            "2 | 30 | 2 | 10.0\n",
            "3 | 30 | 2 | 10.0\n",
            "4 | 30 | 1 | 8.0\n",
            "5 | 30 | 1 | 8.0\n",
            "6 | 30 | 1 | 8.0\n",
            "7 | 30 | 1 | 8.0\n",
            "8 | 30 | 1 | 8.0\n",
            "9 | 30 | 1 | 8.0\n"
          ]
        }
      ],
      "source": [
        "# fill in with Python\n",
        "from math import exp, factorial\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "def poisson_pmf(k: int, lam: float) -> float:\n",
        "    return exp(-lam) * (lam ** k) / factorial(k)\n",
        "\n",
        "\n",
        "def solve_dynamic_pricing(\n",
        "    T: int,\n",
        "    M: int,\n",
        "    prices: List[float],\n",
        "    lambdas: List[float],) -> Tuple[List[List[float]], List[List[int]]]:\n",
        "\n",
        "    N = len(prices)\n",
        "\n",
        "    V: List[List[float]] = [[0.0] * (M + 1) for _ in range(T + 1)]\n",
        "    policy: List[List[int]] = [[0] * (M + 1) for _ in range(T)]\n",
        "    K_MAX = M + 20\n",
        "\n",
        "\n",
        "    pmf_table: List[List[float]] = []\n",
        "    for i in range(N):\n",
        "        row = [poisson_pmf(k, lambdas[i]) for k in range(K_MAX + 1)]\n",
        "        pmf_table.append(row)\n",
        "\n",
        "\n",
        "    for t in range(T - 1, -1, -1):\n",
        "        for inv in range(1, M + 1):\n",
        "            best_val = -1e18\n",
        "            best_action = 0\n",
        "\n",
        "            for i in range(N):\n",
        "\n",
        "                q_val = 0.0\n",
        "                for k in range(min(inv, K_MAX + 1)):\n",
        "                    revenue_today = prices[i] * k\n",
        "                    future_inv = inv - k\n",
        "                    q_val += pmf_table[i][k] * (revenue_today + V[t + 1][future_inv])\n",
        "                tail_prob = 1.0 - sum(pmf_table[i][k] for k in range(min(inv, K_MAX + 1)))\n",
        "                revenue_sellout = prices[i] * inv\n",
        "\n",
        "                q_val += tail_prob * revenue_sellout\n",
        "\n",
        "                if q_val > best_val:\n",
        "                    best_val = q_val\n",
        "                    best_action = i\n",
        "\n",
        "            V[t][inv] = best_val\n",
        "            policy[t][inv] = best_action\n",
        "\n",
        "    return V, policy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    T = 10\n",
        "    M = 30\n",
        "    prices = [5.0, 8.0, 10.0, 12.0, 15.0]\n",
        "    lambdas = [8.0, 5.0, 3.5, 2.5, 1.5]\n",
        "\n",
        "    V, policy = solve_dynamic_pricing(T=T, M=M, prices=prices, lambdas=lambdas)\n",
        "    for t in range(T):\n",
        "        inv = M\n",
        "        idx = policy[t][inv]\n",
        "        print(f\"{t} | {inv} | {idx} | {prices[idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3T27PNNtcHm"
      },
      "source": [
        "## Question 4: Risk-Aversion and Utility Optimization under CARA Utility (Led by Shunyu Yao)\n",
        "\n",
        "You are tasked with analyzing the behavior of an investor who seeks to maximize their utility under **CARA Utility**. The investor has wealth $W$ and the CARA utility function:\n",
        "\n",
        "$$\n",
        "U(W) = \\frac{1 - e^{-aW}}{a}, \\quad a > 0,\n",
        "$$\n",
        "\n",
        "where $a$ represents the investor's **risk aversion**.\n",
        "\n",
        "The investor allocates their wealth between:\n",
        "1. A **riskless asset** with a fixed return $r$, and\n",
        "2. A **risky asset** with return $R \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
        "\n",
        "The investor allocates a fraction $\\pi$ of their wealth to the risky asset and $(1 - \\pi)$ to the riskless asset. The wealth $W$ after one year is given by:\n",
        "\n",
        "$$\n",
        "W = (1 + r)(1 - \\pi) + (1 + R)\\pi.\n",
        "$$\n",
        "\n",
        "The goal is to analyze the investor’s optimal allocation $\\pi$ to the risky asset and compute key risk-related quantities.\n",
        "\n",
        "---\n",
        "\n",
        "### Subquestions\n",
        "\n",
        "#### Part (A): Expected Utility and Certainty-Equivalent Wealth\n",
        "\n",
        "1. Derive the expression for the **expected utility** $\\mathbb{E}[U(W)]$, using the given CARA utility function and assuming $R \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
        "2. Using a Taylor expansion, approximate the **certainty-equivalent wealth** $W_{CE}$ up to second-order terms.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (B): Optimal Portfolio Allocation\n",
        "\n",
        "Derive the optimal fraction $\\pi^*$ of wealth to be allocated to the risky asset such that the **expected utility** $\\mathbb{E}[U(W)]$ is maximized. Express $\\pi^*$ in terms of $a$, $\\mu$, $r$, and $\\sigma^2$.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (C): Risk Premium\n",
        "\n",
        "1. Using the results from Part (A), calculate the **absolute risk premium** $\\pi_A = \\mathbb{E}[W] - W_{CE}$.\n",
        "2. Verify that $\\pi_A \\approx \\frac{a \\pi^2 \\sigma^2}{2}$ for small $\\sigma^2$.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (D): Numerical Calculations and Interpretation\n",
        "\n",
        "Given the parameters $r = 0.02$, $\\mu = 0.08$, $\\sigma^2 = 0.04$, and $a = 3$:\n",
        "1. Compute the optimal allocation $\\pi^*$.\n",
        "2. Calculate the certainty-equivalent wealth $W_{CE}$.\n",
        "3. Compute the absolute risk premium $\\pi_A$.\n",
        "4. Interpret the results and discuss how changes in $a$ and $\\sigma^2$ affect the risk premium and portfolio allocation.\n",
        "\n",
        "---\n",
        "\n",
        "#### Part (E): Expected Utility under Uniform Distribution\n",
        "\n",
        "Now assume that the return of the risky asset, $R$, is no longer normally distributed. Instead, $R \\sim \\text{Uniform}[\\alpha, \\beta]$, where $\\alpha$ and $\\beta$ are the lower and upper bounds of the distribution, respectively.\n",
        "\n",
        "1. Derive the new expression for the **expected utility** $\\mathbb{E}[U(W)]$. Make sure to simplify your result as much as possible, and ensure that it explicitly depends on $a$, $\\pi$, $\\alpha$, $\\beta$, and $r$.\n",
        "\n",
        "**Hint**: Use the fact that if $W \\sim \\text{Uniform}[w_{\\text{min}}, w_{\\text{max}}]$, then:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[g(W)] = \\frac{1}{w_{\\text{max}} - w_{\\text{min}}} \\int_{w_{\\text{min}}}^{w_{\\text{max}}} g(W) \\, dW.\n",
        "$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UT9TyW0tcHm"
      },
      "source": [
        "### Part (A) Answer\n",
        "\n",
        "<span style=\"color:red\">Let $W=(1+r)+\\pi(R-r)$, so $\\mu_W=1+r+\\pi(\\mu-r)$ and $\\sigma_W^2=\\pi^2\\sigma^2$. Then\n",
        "$$\n",
        "\\mathbb{E}[U(W)] = \\frac{1}{a}\\left(1-\\exp\\left(-a\\mu_W+\\frac{a^2\\sigma_W^2}{2}\\right)\\right).\n",
        "$$\n",
        "Using a second-order Taylor expansion of $U$ around $\\mu_W$,\n",
        "$$\n",
        "W_{CE}\\approx \\mu_W-\\frac{a}{2}\\sigma_W^2.\n",
        "$$</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cRN3CAJtcHm"
      },
      "source": [
        "### Part (B) Answer\n",
        "\n",
        "<span style=\"color:red\">Maximizing $\\mathbb{E}[U(W)]$ is equivalent to maximizing the certainty-equivalent\n",
        "$$\n",
        "\\mu_W-\\frac{a}{2}\\sigma_W^2=(1+r)+\\pi(\\mu-r)-\\frac{a}{2}\\pi^2\\sigma^2.\n",
        "$$\n",
        "Find the policy 𝜋 that maximizes the expression$$\n",
        "\\pi^*=\\frac{\\mu-r}{a\\sigma^2}.\n",
        "$$</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrHCSua-tcHn"
      },
      "source": [
        "### Part (C) Answer\n",
        "\n",
        "<span style=\"color:red\">The absolute risk premium is\n",
        "$$\n",
        "\\pi_A=\\mathbb{E}[W]-W_{CE}=\\frac{a}{2}\\sigma_W^2=\\frac{a}{2}\\pi^2\\sigma^2.\n",
        "$$\n",
        "Thus, for small $\\sigma^2$, $\\pi_A\\approx \\frac{a\\pi^2\\sigma^2}{2}$ as required.\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm1DTIj2tcHn"
      },
      "source": [
        "### Part (D) Answer\n",
        "\n",
        "<span style=\"color:red\">  \n",
        "\n",
        "1. $\\pi^*=(0.08-0.02)/(3\\cdot 0.04)=0.5$.  \n",
        "\n",
        "2. $\\mu_W=1.02+0.5\\cdot 0.06=1.05$, $\\sigma_W^2=0.5^2\\cdot 0.04=0.01$, so\n",
        "   $W_{CE}=1.05-\\frac{3}{2}\\cdot 0.01=1.035$.\n",
        "3. $\\pi_A=\\mu_W-W_{CE}=0.015$.\n",
        "4. Higher $a$ or $\\sigma^2$ raises the risk premium and leads to larger allocation in riskless asset.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgr1NhDztcHn"
      },
      "source": [
        "### Part (E) Answer\n",
        "\n",
        "<span style=\"color:red\">With $R\\sim\\text{Uniform}[\\alpha,\\beta]$,\n",
        "$$\n",
        "W=(1+r)+\\pi(R-r),\\quad w_{\\min}=(1+r)+\\pi(\\alpha-r),\\quad w_{\\max}=(1+r)+\\pi(\\beta-r).\n",
        "$$\n",
        "Let $\\Delta w=w_{\\max}-w_{\\min}=\\pi(\\beta-\\alpha)$. Then\n",
        "$$\n",
        "\\mathbb{E}[U(W)]\n",
        "=\\frac{1}{\\Delta w}\\int_{w_{\\min}}^{w_{\\max}}\\frac{1-e^{-aw}}{a}\\,dw\n",
        "=\\frac{1}{a}-\\frac{e^{-a w_{\\min}}-e^{-a w_{\\max}}}{a^2\\,\\pi(\\beta-\\alpha)}.\n",
        "$$</span>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "EVERYTHING_PYTHON",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}